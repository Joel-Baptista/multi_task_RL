project: "Adroit"
total_timesteps: 50_000_000
checkpoints: 1_000
eval_freq: 10_000
record_freq: -1
#record_freq: 100_000

env:
  name: "AdroitHandRelocate-v1"
  args:
    # reward_type: "sparse"
    # tasks_to_complete:
    #   - "microwave"

    # terminate_on_tasks_completed: True
    # remove_task_when_completed: True
    # object_noise_ratio: 0.0005
    # robot_noise_ratio: 0.01
    max_episode_steps: 50
  wraps:
    # - wrap:
    #     name: "reward_wrap"
    #     module: "wraps.reward"
    - wrap:
        name: "correct_success_wrap"
        module: "wraps.reward"
policy: 
  name: "MlpPolicy"
  module: "stable_baselines3.ppo.policies"

algorithm: 
  name: "PPO"
  module: "stable_baselines3"
  args:
    # learning_rate: 0.00003
    # n_steps: 4096
    # batch_size: 64
    # n_epochs: 18
    # gamma: 0.87
    # gae_lambda: 0.99
    # clip_range: 0.1
    # clip_range_vf: Null
    # normalize_advantage: True
    # ent_coef: 0.001
    # vf_coef: 0.5
    # max_grad_norm: 0.5
    # use_sde: False
    # sde_sample_freq: -1
    # target_kl: 0.27
    # seed: Null
    stats_window_size: 1_000
    device: "cuda:1"
    # policy_kwargs:
    #   net_arch: [512, 512, 256, 256]
    #   log_std_init: -1
