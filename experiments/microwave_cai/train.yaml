project: "Kitchen_MultiTask"
total_timesteps: 10_000_000
checkpoints: 1_000
eval_freq: 500
# record_freq: 50
record_freq: 100_000

env:
  name: "FrankaKitchen-v1"
  args:
    tasks_to_complete:
      - "microwave"

    terminate_on_tasks_completed: True
    remove_task_when_completed: True
    object_noise_ratio: 0.0005
    robot_noise_ratio: 0.01
    max_episode_steps: 280
  wraps:
    - wrap:
        name: "reward_wrap"
        module: "wraps.reward"
    - wrap:
        name: "observation_wrap"
        module: "wraps.observation"


policy: 
  name: "SACPolicy"
  module: "stable_baselines3.sac.policies"

algorithm: 
  name: "SAC"
  module: "agents.mb_sac"
  args:
      learning_rate: 0.0003
      buffer_size: 1_000_000
      learning_starts: 256
      batch_size: 256
      tau: 0.005
      gamma: 0.99
      K: 32
      train_freq: 1
      gradient_steps: 1
      lambda_cai: 0.2
      cai_clip: 100
      world_steps_to_train: 500 #-1 to not train
      world_num_updates: 10
      world_batch_size: 512
      ent_coef: auto # Number for fixed, "auto" for learned
      action_noise: Null
      seed: Null
      device: "cuda:1"
      world_model:
        name: "mlp"
        module: "models.world_model"
        pretrained: True
        path: "world_model"
        args:
          hidden_dims: [4048, 2012, 512, 206]
          hidden_activation: "ReLU"
      policy_kwargs:
        net_arch: [512, 256, 256]

