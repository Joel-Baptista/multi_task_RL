project: "Fetch_MultiTask"
total_timesteps: 10_000_000
checkpoints: 2_000
eval_freq: 2_000
record_freq: -1
# record_freq: 100_000

env:
  name: "FetchPickAndPlace-v2"
  args:
    reward_type: "dense"
    # tasks_to_complete:
    #   - "microwave"

    # terminate_on_tasks_completed: True
    # remove_task_when_completed: True
    # object_noise_ratio: 0.0005
    # robot_noise_ratio: 0.01
    max_episode_steps: 100
  wraps:
    - wrap:
        name: "reward_wrap"
        module: "wraps.reward"
    - wrap:
        name: "goal_conditioned_wrap"
        module: "wraps.observation"
policy: 
  name: "SACPolicy"
  module: "stable_baselines3.sac.policies"

algorithm: 
  name: "SAC"
  module: "stable_baselines3"
  args:
      learning_rate: 0.0003
      buffer_size: 1_000_000
      learning_starts: 100
      batch_size: 512
      tau: 0.005
      gamma: 0.99
      train_freq: 1
      gradient_steps: 2
      action_noise: Null
      seed: Null
      device: "cuda:1"
