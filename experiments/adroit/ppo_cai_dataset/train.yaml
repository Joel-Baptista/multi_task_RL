project: "Adroit"
total_timesteps: 50_000_000
checkpoints: 1_000
eval_freq: 10_000
record_freq: 10_000
#record_freq: 100_000

env:
  module: "adroit_reloc"
  # name: "AdroitHandRelocate-v3"
  name: "AdroitHandRelocate-v1"
  path: "envs.adroit_reloc"
  args:
    # reward_type: "sparse"
    # tasks_to_complete:
    #   - "microwave"

    # terminate_on_tasks_completed: True
    # remove_task_when_completed: True
    # object_noise_ratio: 0.0005
    # robot_noise_ratio: 0.01
    max_episode_steps: 50
  wraps:
    # - wrap:
    #     name: "reward_wrap"
    #     module: "wraps.reward"
    - wrap:
        name: "correct_success_wrap"
        module: "wraps.reward"
policy: 
  name: "MlpPolicy"
  module: "stable_baselines3.ppo.policies"

algorithm: 
  name: "MB_PPO_DATASET"
  module: "agents.mb_ppo_dataset"
  args:
    K: 64
    world_steps_to_train: 1 #-1 to not train 
    world_num_updates: 10
    world_batch_size: 512
    lambda_cai: 0.02
    learning_rate: 0.00003
    n_steps: 4096
    batch_size: 64
    n_epochs: 18
    gamma: 0.87
    gae_lambda: 0.99
    clip_range: 0.1
    clip_range_vf: Null
    normalize_advantage: True
    ent_coef: 0.001
    vf_coef: 0.5
    max_grad_norm: 0.5
    use_sde: False
    sde_sample_freq: -1
    target_kl: 0.27
    seed: Null
    stats_window_size: 1_000
    device: "cuda:2"
    world_model:
      name: "mlp"
      module: "models.world_model"
      pretrained: True
      path: "models/Adroit/reloc_world/1"
      partial_obs: [30, 39] #can be Null for full observation
      dataset_name: "adroit-dataset-v1"
      args:
        hidden_dims: [4096, 4096, 4096, 4096, 4096, 2048, 1024, 512]
        hidden_activation: "ReLU"
        dropout: 0.2
        weight_decay: 0.00001
        std: "auto" # "auto" for adaptable; number for fixed
    policy_kwargs:
      net_arch: 
        pi: [512, 256, 256]
        qf: [512, 256, 256]

