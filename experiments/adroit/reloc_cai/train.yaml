project: "Adroit"
total_timesteps: 50_000_000
checkpoints: 1_000
eval_freq: 10_000
record_freq: -1
#record_freq: 100_000

env:
  module: "adroit_reloc"
  # name: "AdroitHandRelocate-v3"
  name: "AdroitHandRelocate-v1"
  path: "envs.adroit_reloc"
  args:
    # reward_type: "sparse"
    # tasks_to_complete:
    #   - "microwave"

    # terminate_on_tasks_completed: True
    # remove_task_when_completed: True
    # object_noise_ratio: 0.0005
    # robot_noise_ratio: 0.01
    max_episode_steps: 50
  wraps:
    # - wrap:
    #     name: "reward_wrap"
    #     module: "wraps.reward"
    - wrap:
        name: "cai_wrap"
        module: "wraps.reward.adroit"

policy: 
  name: "SACPolicy"
  module: "stable_baselines3.sac.policies"

algorithm: 
  name: "SAC"
  module: "agents.mb_sac"
  args:
      learning_rate: 0.0003
      buffer_size: 1_000_000
      learning_starts: 256
      batch_size: 256
      tau: 0.005
      gamma: 0.99
      K: 64
      train_freq: 1
      gradient_steps: 1
      lambda_cai: 0.0002
      cai_clip: Null # Never use clip duh
      world_steps_to_train: 1 #-1 to not train 
      world_num_updates: 1
      world_batch_size: 512
      ent_coef: auto # Number for fixed, "auto" for learned
      action_noise: Null
      seed: Null
      device: "cuda:0"
      model_path: Null
      stats_window_size: 1_000
      world_model:
        name: "mlp"
        module: "models.world_model"
        pretrained: False
        path: Null
        partial_obs: Null #can be Null for full observation
        args:
          hidden_dims: [4096, 4096, 4096, 4096, 4096, 2048, 1024, 512]
          hidden_activation: "ReLU"
          dropout: 0.2
          weight_decay: 0.00001
          std: 0.1 # "auto" for adaptable; number for fixed
      policy_kwargs:
        net_arch: [512, 256, 256]

