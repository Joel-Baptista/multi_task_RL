project: "Fetch_MultiTask"
total_timesteps: 10_000_000
checkpoints: 2_000
eval_freq: 2_000
record_freq: -1
# record_freq: 100_000

env:
  name: "FetchPickAndPlace-v2"
  args:
    reward_type: "sparse"
    # tasks_to_complete:
    #   - "microwave"

    # terminate_on_tasks_completed: True
    # remove_task_when_completed: True
    # object_noise_ratio: 0.0005
    # robot_noise_ratio: 0.01
    max_episode_steps: 100
  wraps:
    - wrap:
        name: "reward_wrap"
        module: "wraps.reward"
        args:
          reward_scale: 1.0
    - wrap:
        name: "goal_conditioned_wrap"
        module: "wraps.observation"

policy: 
  name: "SACPolicy"
  module: "stable_baselines3.sac.policies"

algorithm: 
  args:
    learning_rate: 0.0003
    train_freq: 1
    batch_size: 512
    learning_starts: 1024
    model_path: Null
    world_model_kwargs:
      name: "mlp"
      module: "models.world_model"
      path: Null
      args:
        hidden_dims: [4096, 4096, 4096, 4096, 4096, 2048, 1024, 512]
        hidden_activation: "ReLU"
